{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c277c688",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ | Cora-For-Zava: Model Customization with Fine-Tuning\n",
    "\n",
    "Welcome! This notebook will guide you through customizing an AI model using Supervised Fine-Tuning (SFT) to improve tone, style, and response consistency for your specific use case.\n",
    "\n",
    "## ðŸ›’ Our Zava Scenario\n",
    "\n",
    "**Cora** is a customer service chatbot for **Zava** - a fictitious retailer of home improvement goods for DIY enthusiasts. While we've used few-shot examples and RAG to improve Cora's responses, these approaches increase prompt length (raising token costs and reducing available context window). Fine-tuning allows us to embed better tone and style directly into the model with shorter prompts.\n",
    "\n",
    "## ðŸŽ¯ What You'll Build\n",
    "\n",
    "By the end of this notebook, you'll have:\n",
    "- âœ… Prepared and validated training datasets for fine-tuning\n",
    "- âœ… Analyzed token usage to optimize training efficiency\n",
    "- âœ… Uploaded training data to Azure OpenAI for processing\n",
    "- âœ… Submitted and monitored a fine-tuning job\n",
    "- âœ… Deployed a custom fine-tuned model for testing\n",
    "- âœ… Evaluated the improved tone and style consistency\n",
    "\n",
    "## ðŸ’¡ What You'll Learn\n",
    "\n",
    "- How to prepare JSONL datasets for supervised fine-tuning\n",
    "- How to validate token counts and optimize training data\n",
    "- How to submit and monitor fine-tuning jobs in Azure OpenAI\n",
    "- How to deploy and test fine-tuned models\n",
    "- How fine-tuning reduces prompt length while improving consistency\n",
    "- When to use fine-tuning vs. few-shot prompting vs. RAG\n",
    "\n",
    "> **Note**: Fine-tuning customizes model behavior at the foundation level, allowing shorter prompts while maintaining quality and consistency.\n",
    "\n",
    "Ready to customize your model? Let's get started! ðŸš€\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e60caa",
   "metadata": {},
   "source": [
    "## Step 1: Verify Environment Variables\n",
    "\n",
    "The following environment variables should already be configured in your `.env` file from the earlier setup steps:\n",
    "\n",
    "- **AZURE_OPENAI_API_KEY**: Your Azure OpenAI API key\n",
    "- **AZURE_OPENAI_ENDPOINT**: Your Azure OpenAI service endpoint\n",
    "- **AZURE_OPENAI_API_VERSION**: The API version to use (2025-02-01-preview for fine-tuning)\n",
    "- **AZURE_SUBSCRIPTION_ID**: Your Azure subscription ID\n",
    "- **AZURE_RESOURCE_GROUP**: Your Azure resource group name\n",
    "- **AZURE_AI_PROJECT_NAME**: Your Azure AI Foundry project name\n",
    "\n",
    "> **Important**: Fine-tuning requires specific API versions and model availability. Currently, `gpt-4o-2024-08-06` can be fine-tuned in Sweden Central and North Central US regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495e2ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "model_name = \"gpt-4.1\"\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2025-02-01-preview\")\n",
    "\n",
    "if not openai_key or not openai_endpoint:\n",
    "    print(\"Error: Missing AZURE_OPENAI_KEY or AZURE_OPENAI_ENDPOINT environment variable.\")\n",
    "\n",
    "print(\"Using Model:\", model_name)\n",
    "print(\"Using API Version:\", api_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae8408",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Training Dataset\n",
    "\n",
    "Fine-tuning requires carefully prepared training data in JSONL format. Each line contains a conversation example with the desired tone and style. Our dataset includes:\n",
    "\n",
    "- **Training Set** (`31-basic_training.jsonl`): Examples for model learning\n",
    "- **Validation Set** (`31-basic_validation.jsonl`): Examples for performance monitoring during training\n",
    "\n",
    "> **Key Format Requirements**:\n",
    "> - Each example must have a `messages` array with conversation turns\n",
    "> - Messages include `role` (system/user/assistant) and `content`\n",
    "> - Training examples should demonstrate the desired Zava tone: polite, factual, helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d21d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Training and Validation datafiles\n",
    "\n",
    "\n",
    "training_file = \"./31-basic_training.jsonl\" \n",
    "validation_file = \"./31-basic_validation.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9fb115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run preliminary checks\n",
    "\n",
    "import json\n",
    "\n",
    "# Load the training set\n",
    "with open(training_file, 'r', encoding='utf-8') as f:\n",
    "    training_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in training set:\", len(training_dataset))\n",
    "print(\"First example in training set:\")\n",
    "for message in training_dataset[0][\"messages\"]:\n",
    "    print(message)\n",
    "\n",
    "# Load the validation set\n",
    "with open(validation_file, 'r', encoding='utf-8') as f:\n",
    "    validation_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Validation dataset stats\n",
    "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
    "print(\"First example in validation set:\")\n",
    "for message in validation_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345304de",
   "metadata": {},
   "source": [
    "## Step 3: Assess Token Counts For Data\n",
    "\n",
    "Token analysis is crucial for fine-tuning cost estimation and quality. We'll analyze:\n",
    "\n",
    "- **Total Tokens**: Complete conversation length including system, user, and assistant messages\n",
    "- **Assistant Tokens**: Only the model's responses (what we're training to improve)\n",
    "- **Distribution Statistics**: Min/max, mean/median, and percentile analysis\n",
    "\n",
    "> **Best Practices**:\n",
    "> - Keep conversations focused and concise\n",
    "> - Aim for consistent token lengths across examples\n",
    "> - Monitor assistant token ratio for cost optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d106f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate token counts\n",
    "\n",
    "import json\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"o200k_base\") # default encoding for gpt-4o models. This requires the latest version of tiktoken to be installed.\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "files = [training_file, validation_file]\n",
    "\n",
    "for file in files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "\n",
    "    total_tokens = []\n",
    "    assistant_tokens = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        messages = ex.get(\"messages\", {})\n",
    "        total_tokens.append(num_tokens_from_messages(messages))\n",
    "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "    print_distribution(total_tokens, \"total tokens\")\n",
    "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
    "    print('*' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b023e173",
   "metadata": {},
   "source": [
    "## Step 4: Upload Fine-Tuning Data To Azure\n",
    "\n",
    "Upload your prepared datasets to Azure OpenAI for processing. The uploaded files will be:\n",
    "\n",
    "- **Stored securely** in your Azure OpenAI resource\n",
    "- **Validated automatically** for format compliance\n",
    "- **Accessible** for fine-tuning job creation\n",
    "- **Visible** in Azure AI Foundry Portal under 'Data Files'\n",
    "\n",
    "> **Security Note**: Data is encrypted at rest and in transit. Files are only accessible within your Azure OpenAI resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d2747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Azure OpenAI Client\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "  api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11fc1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
    "# Note: You can visit the Azure AI Foundry Portal - and look under your Azure AI Project's 'Data Files' tab to see the uploaded files.\n",
    "\n",
    "training_response = client.files.create(\n",
    "    file = open(training_file, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response.id\n",
    "\n",
    "validation_response = client.files.create(\n",
    "    file = open(validation_file, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bee32c",
   "metadata": {},
   "source": [
    "## Step 5: Submit The Fine-Tuning Job\n",
    "\n",
    "Create and submit a fine-tuning job with your uploaded datasets. Key parameters:\n",
    "\n",
    "- **Base Model**: `gpt-4o-2024-08-06` (fine-tuning compatible version)\n",
    "- **Training File**: Your uploaded training dataset\n",
    "- **Validation File**: Your uploaded validation dataset  \n",
    "- **Seed**: For reproducible results (optional but recommended)\n",
    "\n",
    "> **Important**: Fine-tuning jobs typically take 10-30 minutes depending on dataset size. The job will automatically create training checkpoints and monitor validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ddf91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit fine-tuning training job\n",
    "# Add a delay so the cell runs for about 1 minute\n",
    "import time\n",
    "time.sleep(60)\n",
    "\n",
    "# Note that the model you specify here must be one that can be fine-tuned.\n",
    "# Currently gpt-4o can be fine-tuned only in Sweden Central and North Central US\n",
    "# See: https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/fine-tuning?tabs=azure-openai&pivots=programming-language-python#prerequisites\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-4o-2024-08-06\", # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters.\n",
    "    seed = 105,  # seed parameter controls reproducibility of the fine-tuning job. If no seed is specified one will be generated automatically.\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.id)\n",
    "print(response.model_dump_json(indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f468e4f3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Track Fine-Tuning Job Status\n",
    "\n",
    "Monitor your fine-tuning job progress in real-time. The job progresses through these stages:\n",
    "\n",
    "1. **Validating**: Checking data format and compatibility\n",
    "2. **Running**: Active training with your dataset\n",
    "3. **Succeeded**: Training completed successfully\n",
    "4. **Failed**: Training encountered an error\n",
    "\n",
    "> **Monitoring**: The cell will automatically refresh every 10 seconds until completion. You can also view progress in the Azure AI Foundry Portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track training status\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "status = response.status\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(10)\n",
    "\n",
    "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = response.status\n",
    "    print(f'Status: {status}')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f'Fine-tuning job {job_id} finished with status: {status}')\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print('Checking other fine-tune jobs for this resource.')\n",
    "response = client.fine_tuning.jobs.list()\n",
    "print(f'Found {len(response.data)} fine-tune jobs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81343ca5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7: Review Fine-Tuning Events\n",
    "\n",
    "Examine detailed training events and logs to understand the training process:\n",
    "\n",
    "- **Training Progress**: Step-by-step training updates\n",
    "- **Loss Metrics**: Training and validation loss evolution\n",
    "- **Completion Status**: Final training results and model location\n",
    "\n",
    "> **Debugging**: Events help troubleshoot any training issues and verify successful completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe8fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509896ba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 8: Review Fine-Tuning Checkpoints\n",
    "\n",
    "Examine training checkpoints created during the fine-tuning process:\n",
    "\n",
    "- **Checkpoint Analysis**: Model state at different training steps\n",
    "- **Performance Metrics**: Validation loss at each checkpoint\n",
    "- **Model Selection**: Identify the best performing checkpoint\n",
    "\n",
    "> **Advanced Usage**: Checkpoints allow you to select optimal training stopping points and analyze training dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7088ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.fine_tuning.jobs.checkpoints.list(job_id)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b3e13f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42313dcc",
   "metadata": {},
   "source": [
    "## Step 9: Retrieve Fine-Tuned Model Name\n",
    "\n",
    "Get your completed fine-tuned model identifier for deployment:\n",
    "\n",
    "- **Model ID**: Unique identifier for your custom model\n",
    "- **Training Stats**: Final training metrics and completion details\n",
    "- **Deployment Ready**: Model is ready for Azure deployment\n",
    "\n",
    "> **Next Step**: Use this model ID to create a deployment in Azure AI Foundry Portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a77c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve fine_tuned_model name\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(response.model_dump_json(indent=2))\n",
    "fine_tuned_model = response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39afff9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 10: Deploy Fine-Tuned Model For Testing\n",
    "\n",
    "Deploy your fine-tuned model to test the improved tone and style:\n",
    "\n",
    "1. **Azure AI Foundry Portal**: Navigate to your project's Model deployments\n",
    "2. **Deploy Custom Model**: Select your fine-tuned model ID\n",
    "3. **Developer Tier**: Use for testing (inference costs only, no hosting fees)\n",
    "4. **Configure Deployment**: Set deployment name and resource allocation\n",
    "\n",
    "> **Cost Optimization**: Developer tier allows testing without hosting costs. Upgrade to standard deployment for production use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85182ed",
   "metadata": {},
   "source": [
    "> Prompt 1: What kind of paint should I buy for my outdoor deck?\n",
    "\n",
    "```txt\n",
    "ðŸªµ Deck protection options! Semi-Transparent Deck Stain at 38 enhances wood grain, or Deck & Fence Stain at 36 for UV protection?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892334a4",
   "metadata": {},
   "source": [
    "> Prompt 2: I'm painting over rust - what spray paint should I use?\n",
    "\n",
    "ðŸ‘ Right choice! Rust Prevention Spray at $13 applies directly over rust with long-lasting protection. Primer recommendation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a39c0bb",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Fine-Tuning Results & Insights\n",
    "\n",
    "**Zava Tone Consistency Achieved!**\n",
    "\n",
    "In both examples above, the fine-tuned model now consistently follows Zava's brand guidelines for \"polite, factual, and helpful\" responses:\n",
    "\n",
    "### âœ… Consistent Structure\n",
    "- **Emoji Opening**: Every response starts with a relevant emoji\n",
    "- **Polite Acknowledgment**: First sentence acknowledges the customer's need\n",
    "- **Factual Information**: Middle section provides specific product details and pricing\n",
    "- **Helpful Follow-up**: Final sentence offers additional assistance\n",
    "\n",
    "### ðŸš€ Key Benefits Achieved\n",
    "- **Shorter Prompts**: No need for few-shot examples in every request\n",
    "- **Lower Token Costs**: Reduced prompt length saves on API costs\n",
    "- **Faster Processing**: Less context to process means faster responses\n",
    "- **Consistent Quality**: Every response follows the trained pattern\n",
    "\n",
    "### ðŸ“Š Performance Comparison\n",
    "| Aspect | Before Fine-Tuning | After Fine-Tuning |\n",
    "|--------|--------------------|--------------------|\n",
    "| Prompt Length | ~800 tokens (with examples) | ~200 tokens (system prompt only) |\n",
    "| Tone Consistency | Variable (depends on examples) | Consistent (embedded in model) |\n",
    "| Response Time | Slower (longer prompt) | Faster (shorter prompt) |\n",
    "| Cost per Request | Higher (more input tokens) | Lower (fewer input tokens) |\n",
    "\n",
    "> **Best Practice**: Fine-tuning is most effective when you have consistent patterns you want the model to learn, rather than just providing factual knowledge (which is better handled by RAG)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7621cf2b",
   "metadata": {},
   "source": [
    "## Step 11: Next Steps\n",
    "\n",
    "You've successfully fine-tuned a model for better tone and style! Here are your next steps:\n",
    "\n",
    "> **Key Insight**: Fine-tuning excels at embedding consistent patterns (like tone and style) while RAG excels at providing up-to-date factual information. Combining both creates powerful, cost-effective AI systems.\n",
    "\n",
    "---\n",
    "\n",
    "**Great work! You've mastered fine-tuning for tone and style customization.** ðŸŽ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54567f40",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
