{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b708ee07",
   "metadata": {},
   "source": [
    "# üé® Introduction to Model Customization\n",
    "\n",
    "## üõí The Zava Scenario\n",
    "\n",
    "Cora is working well with a base model, but Zava wants it to provide responses that are more aligned with their brand voice, home improvement terminology, and customer service guidelines. Generic models may not capture the specific nuances of home improvement retail.\n",
    "\n",
    "**The Opportunity**: Instead of relying solely on prompt engineering, we can customize the model itself through techniques like fine-tuning and distillation to make Cora more specialized for Zava's home improvement retail needs.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "In this section, you'll understand:\n",
    "\n",
    "1. **Few-shot prompting** - Teaching models through examples in the prompt\n",
    "2. **Supervised Fine-Tuning (SFT)** - Training models on domain-specific data\n",
    "3. **Distillation** - Transferring knowledge from larger to smaller models\n",
    "4. **Data preparation for fine-tuning** - JSONL format and best practices\n",
    "5. **When to use each customization technique** - Trade-offs and use cases\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "Model customization enables you to:\n",
    "- **Improve response quality** for domain-specific tasks\n",
    "- **Reduce costs** by using smaller, specialized models\n",
    "- **Align outputs** with brand voice and guidelines\n",
    "- **Handle specialized terminology** unique to your business\n",
    "\n",
    "Let's explore how to customize models to make Cora more effective for Zava's home improvement retail business.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6e8cba",
   "metadata": {},
   "source": [
    "## Why Customize Models?\n",
    "\n",
    "Base models (GPT-4o, GPT-4o-mini) are trained on general internet data. They're powerful but generic.\n",
    "\n",
    "**Problems with base models:**\n",
    "\n",
    "### 1. Inconsistent Tone/Style\n",
    "\n",
    "**Customer:** \"What paint do you have?\"\n",
    "\n",
    "**Base Model:** \"We have various paint options including interior, exterior, latex, oil-based...\"\n",
    "\n",
    "**Custom Model (Zava style):** \"Great question! We have several excellent paint options for your project. Let me help you find the perfect match...\"\n",
    "\n",
    "The custom model maintains Zava's friendly, helpful brand voice consistently.\n",
    "\n",
    "### 2. Domain Knowledge Gaps\n",
    "\n",
    "**Customer:** \"I need paint for T1-11 siding\"\n",
    "\n",
    "**Base Model:** \"I can help you find paint. What color are you looking for?\"\n",
    "\n",
    "**Custom Model:** \"For T1-11 siding, you'll want a high-quality exterior acrylic latex paint with good penetration. Our Premium Exterior Paint (PFIP000002) is perfect for this application...\"\n",
    "\n",
    "The custom model understands hardware/construction terminology.\n",
    "\n",
    "### 3. Long Prompts\n",
    "\n",
    "**Without customization:** Need to include examples in every prompt\n",
    "```\n",
    "Prompt (500 tokens):\n",
    "\"You are Cora, a helpful Zava assistant. Examples:\n",
    "Q: What paint? A: [example]\n",
    "Q: What drill? A: [example]\n",
    "...\n",
    "Now answer: What paint do you have?\"\n",
    "```\n",
    "\n",
    "**With customization:** Model \"knows\" the style already\n",
    "```\n",
    "Prompt (50 tokens):\n",
    "\"You are Cora. Customer asks: What paint do you have?\"\n",
    "```\n",
    "\n",
    "**Result:** Significant token reduction leads to lower costs at scale\n",
    "\n",
    "### 4. Response Consistency\n",
    "\n",
    "**Base model responses vary:**\n",
    "- Query 1: Formal and technical\n",
    "- Query 2: Casual and brief  \n",
    "- Query 3: Overly detailed\n",
    "\n",
    "**Custom model:** Consistent tone, structure, and detail level across all responses\n",
    "\n",
    "## Customization Approaches\n",
    "\n",
    "There are three main ways to customize model behavior:\n",
    "\n",
    "| Approach | What It Does | Best For | Cost | Effort |\n",
    "|----------|--------------|----------|------|--------|\n",
    "| **Few-Shot Prompting** | Include examples in prompt | Quick testing, dynamic examples | Low (pay per token) | Low |\n",
    "| **Fine-Tuning** | Train model on your data | Consistent style, domain knowledge | Medium (one-time training) | Medium |\n",
    "| **Distillation** | Transfer knowledge from larger model | Cost optimization, efficiency | Low-Medium | High |\n",
    "\n",
    "We'll explore each in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8182bc9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Few-Shot Prompting\n",
    "\n",
    "**Few-shot prompting** means including example query-response pairs in your prompt to guide the model's behavior.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "You are Cora, a helpful Zava Hardware assistant.\n",
    "\n",
    "Example 1:\n",
    "Customer: What paint do you have?\n",
    "Cora: Great question! We have several excellent paint options. For interior \n",
    "projects, I recommend our Premium Interior Paint. For exterior, our Premium \n",
    "Exterior Paint is weather-resistant and durable. What's your project?\n",
    "\n",
    "Example 2:\n",
    "Customer: Is PFIP000002 in stock?\n",
    "Cora: Yes! Premium Exterior Paint (SKU: PFIP000002) is currently in stock \n",
    "with 75 units available. Would you like me to help you with anything else?\n",
    "\n",
    "Now answer:\n",
    "Customer: {user_query}\n",
    "Cora:\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**The model learns from examples** and mimics the style.\n",
    "\n",
    "### Pros\n",
    "\n",
    "‚úÖ **Quick to implement** - No training required  \n",
    "‚úÖ **Flexible** - Change examples anytime  \n",
    "‚úÖ **No infrastructure** - Just modify prompts  \n",
    "‚úÖ **Dynamic** - Different examples for different scenarios\n",
    "\n",
    "### Cons\n",
    "\n",
    "‚ùå **Increases token costs** - Examples add 200-500 tokens per request  \n",
    "‚ùå **Uses context window** - Less room for actual conversation  \n",
    "‚ùå **Not as consistent** - Model still improvises  \n",
    "‚ùå **Limited examples** - Can only fit 5-10 examples\n",
    "\n",
    "### When to Use Few-Shot\n",
    "\n",
    "- ‚úÖ Prototyping and testing\n",
    "- ‚úÖ Need flexibility (examples change often)\n",
    "- ‚úÖ Low query volume (< 1000/day)\n",
    "- ‚úÖ Simple behavior changes\n",
    "- ‚ùå High query volume (expensive)\n",
    "- ‚ùå Need perfect consistency\n",
    "- ‚ùå Complex domain knowledge required\n",
    "\n",
    "### Example Calculation\n",
    "\n",
    "**Scenario:** 10,000 queries/day with 5 examples (300 tokens)\n",
    "\n",
    "```\n",
    "Few-Shot Approach:\n",
    "- Higher token usage per request (examples included)\n",
    "- Pay-per-use model\n",
    "- Costs scale linearly with volume\n",
    "\n",
    "Fine-Tuning Approach:\n",
    "- Lower token usage per request (no examples needed)\n",
    "- One-time training cost\n",
    "- Lower per-request inference cost\n",
    "\n",
    "At high volumes, fine-tuning becomes more cost-effective.\n",
    "\n",
    "**Conclusion:** Few-shot works for low volume; fine-tuning better at scale.\n",
    "\n",
    "For current pricing: https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b6eea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fine-Tuning\n",
    "\n",
    "**Fine-tuning** means continuing to train a base model on your specific data, adjusting its internal parameters to learn your domain and style.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "```\n",
    "Base Model (GPT-4o-mini)\n",
    "         ‚Üì\n",
    "    + Your Training Data\n",
    "      (100-1000 examples)\n",
    "         ‚Üì\n",
    "   Fine-Tuning Process\n",
    "   (2-6 hours on Azure)\n",
    "         ‚Üì\n",
    "   Custom Fine-Tuned Model\n",
    "   (your-model-deployment)\n",
    "```\n",
    "\n",
    "**The model's weights are updated** to encode your patterns directly.\n",
    "\n",
    "### What Gets Trained\n",
    "\n",
    "**Training data format (JSONL):**\n",
    "\n",
    "```jsonl\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are Cora, a Zava assistant\"}, {\"role\": \"user\", \"content\": \"What paint do you have?\"}, {\"role\": \"assistant\", \"content\": \"Great question! We have several excellent paint options...\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are Cora, a Zava assistant\"}, {\"role\": \"user\", \"content\": \"Is PFIP000002 in stock?\"}, {\"role\": \"assistant\", \"content\": \"Yes! Premium Exterior Paint is currently in stock...\"}]}\n",
    "```\n",
    "\n",
    "Each line is a complete conversation example showing:\n",
    "1. System instructions\n",
    "2. User query\n",
    "3. Expected assistant response\n",
    "\n",
    "**The model learns:**\n",
    "- Response style and tone\n",
    "- Domain terminology\n",
    "- Response structure and format\n",
    "- Brand voice and personality\n",
    "\n",
    "### Supervised Fine-Tuning (SFT)\n",
    "\n",
    "**SFT** is the most common fine-tuning approach:\n",
    "\n",
    "1. **Supervised** - You provide labeled examples (query ‚Üí expected response)\n",
    "2. **Learning objective** - Model learns to predict your responses given inputs\n",
    "3. **Gradient descent** - Model weights adjusted to minimize error on your data\n",
    "\n",
    "**Analogy:** Like tutoring a student with practice problems and answer keys.\n",
    "\n",
    "### Preparing Training Data\n",
    "\n",
    "**Data requirements:**\n",
    "- **Minimum:** 50 examples (more is better)\n",
    "- **Recommended:** 100-1000 examples\n",
    "- **Format:** JSONL (JSON Lines)\n",
    "- **Quality:** High-quality examples only\n",
    "\n",
    "**Data sources:**\n",
    "1. **Real conversations** (if available)\n",
    "2. **Synthetic generation** (using Azure AI Simulator)\n",
    "3. **Manual curation** (expert-written examples)\n",
    "4. **Hybrid** (real + augmented)\n",
    "\n",
    "**Example generation:**\n",
    "\n",
    "```python\n",
    "training_data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": \"What paint is best for kitchens?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"For kitchens, I recommend our Premium Interior Paint...\"}\n",
    "        ]\n",
    "    },\n",
    "    # ... 99 more examples\n",
    "]\n",
    "\n",
    "# Save as JSONL\n",
    "with open(\"training.jsonl\", \"w\") as f:\n",
    "    for item in training_data:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "```\n",
    "\n",
    "### Token Optimization\n",
    "\n",
    "**Problem:** Training cost based on token count\n",
    "\n",
    "**Formula:**\n",
    "```\n",
    "Training Cost = (Total Tokens in Dataset) √ó (Training Epochs) √ó (Price per Token)\n",
    "```\n",
    "\n",
    "**Optimization strategies:**\n",
    "\n",
    "1. **Remove redundancy**\n",
    "```python\n",
    "# Before (verbose)\n",
    "\"Hello! Thank you for asking! I'm happy to help you with that question...\"\n",
    "\n",
    "# After (concise)\n",
    "\"I recommend our Premium Exterior Paint for outdoor wood projects...\"\n",
    "```\n",
    "\n",
    "2. **Truncate long responses**\n",
    "```python\n",
    "# Keep responses under 150 tokens\n",
    "if token_count(response) > 150:\n",
    "    response = truncate_intelligently(response, 150)\n",
    "```\n",
    "\n",
    "3. **Validate before uploading**\n",
    "```python\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Check token counts\n",
    "total_tokens = sum(count_tokens(ex) for ex in training_data)\n",
    "cost_estimate = (total_tokens * epochs * price_per_1k) / 1000\n",
    "\n",
    "print(f\"Estimated training cost: ${cost_estimate:.2f}\")\n",
    "```\n",
    "\n",
    "### Fine-Tuning Process\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. **Prepare data** (JSONL format)\n",
    "2. **Upload to Azure OpenAI**\n",
    "3. **Submit fine-tuning job**\n",
    "4. **Monitor progress** (2-6 hours)\n",
    "5. **Deploy fine-tuned model**\n",
    "6. **Test and validate**\n",
    "\n",
    "**Azure OpenAI fine-tuning job:**\n",
    "\n",
    "```python\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(...)\n",
    "\n",
    "# Upload training file\n",
    "with open(\"training.jsonl\", \"rb\") as f:\n",
    "    training_file = client.files.create(file=f, purpose=\"fine-tune\")\n",
    "\n",
    "# Create fine-tuning job\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",  # Base model\n",
    "    hyperparameters={\n",
    "        \"n_epochs\": 3  # Number of training passes\n",
    "    }\n",
    ")\n",
    "\n",
    "# Monitor\n",
    "status = client.fine_tuning.jobs.retrieve(job.id)\n",
    "print(f\"Status: {status.status}\")\n",
    "```\n",
    "\n",
    "### Pros\n",
    "\n",
    "‚úÖ **Shorter prompts** - No need for examples  \n",
    "‚úÖ **Consistent behavior** - Model \"knows\" your style  \n",
    "‚úÖ **Better domain knowledge** - Learns terminology  \n",
    "‚úÖ **Cost-effective at scale** - Lower per-query cost  \n",
    "‚úÖ **Improved quality** - Specialized for your use case\n",
    "\n",
    "### Cons\n",
    "\n",
    "‚ùå **Initial effort** - Requires creating training data  \n",
    "‚ùå **Training time** - 2-6 hours per job  \n",
    "‚ùå **Static knowledge** - Must retrain to update  \n",
    "‚ùå **Versioning complexity** - Managing model versions\n",
    "\n",
    "### When to Use Fine-Tuning\n",
    "\n",
    "- ‚úÖ High query volume (> 1000/day)\n",
    "- ‚úÖ Need consistent tone/style\n",
    "- ‚úÖ Domain-specific terminology\n",
    "- ‚úÖ Have quality training data\n",
    "- ‚úÖ Long-term deployment\n",
    "- ‚ùå Data changes daily\n",
    "- ‚ùå Need real-time updates\n",
    "- ‚ùå Very low query volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b539278",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Distillation\n",
    "\n",
    "**Distillation** means training a smaller, faster model to mimic a larger, more capable model.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "```\n",
    "Large \"Teacher\" Model          Small \"Student\" Model\n",
    "(Higher cost/better)    ‚Üí      (Lower cost/faster)\n",
    "                                     \n",
    "Query: \"What paint?\"    ‚Üí      Query: \"What paint?\"\n",
    "Response: [detailed]    ‚Üí      Response: [similar quality]\n",
    "                                     \n",
    "Cost: Higher per token         Cost: Lower per token\n",
    "Latency: Slower                Latency: Faster\n",
    "\n",
    "See pricing: https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/\n",
    "```\n",
    "\n",
    "**Goal:** Get GPT-4o quality at GPT-4o-mini cost/speed.\n",
    "\n",
    "### Distillation Process\n",
    "\n",
    "**Step 1: Generate Teacher Responses**\n",
    "\n",
    "```python\n",
    "# Use large model to generate high-quality responses\n",
    "teacher_model = \"gpt-4o\"\n",
    "student_training_data = []\n",
    "\n",
    "for query in training_queries:\n",
    "    teacher_response = call_model(teacher_model, query)\n",
    "    student_training_data.append({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "            {\"role\": \"assistant\", \"content\": teacher_response}\n",
    "        ]\n",
    "    })\n",
    "```\n",
    "\n",
    "**Step 2: Fine-Tune Student Model**\n",
    "\n",
    "```python\n",
    "# Fine-tune small model on teacher's responses\n",
    "student_model = fine_tune(\n",
    "    base_model=\"gpt-4o-mini\",\n",
    "    training_data=student_training_data\n",
    ")\n",
    "```\n",
    "\n",
    "**Step 3: Evaluate**\n",
    "\n",
    "```python\n",
    "# Compare student vs teacher\n",
    "for query in test_queries:\n",
    "    teacher_response = call_model(\"gpt-4o\", query)\n",
    "    student_response = call_model(student_model, query)\n",
    "    \n",
    "    similarity = compute_similarity(teacher_response, student_response)\n",
    "    print(f\"Similarity: {similarity}\")  # Goal: > 0.85\n",
    "```\n",
    "\n",
    "### Knowledge Transfer\n",
    "\n",
    "**What gets distilled:**\n",
    "- Reasoning patterns\n",
    "- Response structure\n",
    "- Domain knowledge\n",
    "- Task-specific behaviors\n",
    "\n",
    "**What doesn't get distilled:**\n",
    "- Raw intelligence (student has limits)\n",
    "- Emergent capabilities (student is smaller)\n",
    "- Perfect accuracy (some quality loss acceptable)\n",
    "\n",
    "### Types of Distillation\n",
    "\n",
    "**1. Basic Distillation**\n",
    "- Student learns from teacher's outputs directly\n",
    "- Simple, effective for most use cases\n",
    "\n",
    "**2. Distillation with Custom Graders**\n",
    "- Use custom evaluators to score teacher responses\n",
    "- Only keep high-quality examples for student training\n",
    "- Better quality control\n",
    "\n",
    "**Example: Custom grader**\n",
    "\n",
    "```python\n",
    "def grade_response(query, response):\n",
    "    \"\"\"Custom evaluator for response quality\"\"\"\n",
    "    score = 0\n",
    "    \n",
    "    # Check for key elements\n",
    "    if contains_product_sku(response):\n",
    "        score += 1\n",
    "    if polite_tone(response):\n",
    "        score += 1\n",
    "    if factually_grounded(response):\n",
    "        score += 1\n",
    "    if under_token_limit(response, 150):\n",
    "        score += 1\n",
    "        \n",
    "    return score >= 3  # Keep if passes quality threshold\n",
    "\n",
    "# Filter training data\n",
    "high_quality_data = [\n",
    "    ex for ex in distillation_data \n",
    "    if grade_response(ex[\"query\"], ex[\"response\"])\n",
    "]\n",
    "```\n",
    "\n",
    "### Pros\n",
    "\n",
    "‚úÖ **Cost reduction** - Cheaper model with similar quality  \n",
    "‚úÖ **Speed improvement** - Faster inference  \n",
    "‚úÖ **Smaller deployment** - Lower resource requirements  \n",
    "‚úÖ **Quality preservation** - Maintains ~85-95% of teacher quality\n",
    "\n",
    "### Cons\n",
    "\n",
    "‚ùå **Two-step process** - Generate + fine-tune  \n",
    "‚ùå **Quality ceiling** - Can't exceed student model's capacity  \n",
    "‚ùå **Upfront cost** - Expensive to generate teacher responses  \n",
    "‚ùå **Complex evaluation** - Need to validate quality preservation\n",
    "\n",
    "### When to Use Distillation\n",
    "\n",
    "- ‚úÖ Using expensive large model in production\n",
    "- ‚úÖ Need to reduce cost/latency\n",
    "- ‚úÖ Have budget for teacher model generation\n",
    "- ‚úÖ Can accept 5-15% quality reduction\n",
    "- ‚ùå Already using smallest model\n",
    "- ‚ùå Need maximum quality (can't compromise)\n",
    "- ‚ùå Low query volume (ROI too low)\n",
    "\n",
    "### Example ROI Calculation\n",
    "\n",
    "**Scenario:** 100K queries/month\n",
    "Current (Large Model):\n",
    "- Higher per-token cost\n",
    "- Higher monthly operational cost\n",
    "\n",
    "Distillation (Small Model fine-tuned):\n",
    "- One-time generation cost (teacher responses)\n",
    "- One-time training cost\n",
    "- Lower per-token inference cost\n",
    "- Significantly lower monthly operational cost\n",
    "\n",
    "Result: Substantial cost savings at high volume\n",
    "Typical payback period: Days to weeks\n",
    "Annual savings: $15,000\n",
    "For pricing details: https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/\n",
    "\n",
    "```\n",
    "**Conclusion:** Distillation is extremely valuable at high volume.\n",
    "\n",
    "**Conclusion:** Distillation is extremely valuable at high volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c532bfc5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Choosing the Right Approach\n",
    "\n",
    "### Decision Tree\n",
    "\n",
    "```\n",
    "Start: Need to customize model behavior?\n",
    "  ‚Üì\n",
    "  Yes ‚Üí High query volume (> 1000/day)?\n",
    "         ‚Üì\n",
    "         Yes ‚Üí Using expensive model?\n",
    "                ‚Üì\n",
    "                Yes ‚Üí Use DISTILLATION\n",
    "                       (GPT-4o ‚Üí GPT-4o-mini fine-tuned)\n",
    "                ‚Üì\n",
    "                No ‚Üí Use FINE-TUNING\n",
    "                      (GPT-4o-mini base ‚Üí fine-tuned)\n",
    "         ‚Üì\n",
    "         No ‚Üí Need flexibility?\n",
    "               ‚Üì\n",
    "               Yes ‚Üí Use FEW-SHOT PROMPTING\n",
    "               ‚Üì\n",
    "               No ‚Üí Use FINE-TUNING\n",
    "                     (better long-term)\n",
    "```\n",
    "\n",
    "### Comparison Matrix\n",
    "\n",
    "| Factor | Few-Shot | Fine-Tuning | Distillation |\n",
    "|--------|----------|-------------|--------------|\n",
    "| **Setup Time** | Minutes | Hours | Days |\n",
    "| **Query Volume Sweet Spot** | < 1K/day | > 1K/day | > 10K/day |\n",
    "| **Consistency** | Medium | High | High |\n",
    "| **Cost at 10K queries/day** | Higher | Medium | Lower |\n",
    "| **Flexibility** | High | Low | Low |\n",
    "| **Domain Knowledge** | Limited | Good | Good |\n",
    "| **Quality** | Good | Better | Best (if done right) |\n",
    "\n",
    "### Hybrid Approaches\n",
    "\n",
    "**Combine multiple techniques:**\n",
    "\n",
    "**1. Fine-Tuning + RAG**\n",
    "- Fine-tune for tone/style (static)\n",
    "- RAG for product knowledge (dynamic)\n",
    "\n",
    "```python\n",
    "# Fine-tuned model for Zava brand voice\n",
    "model = \"zava-custom-model\"\n",
    "\n",
    "# RAG for up-to-date product info\n",
    "context = retrieve_from_search(query)\n",
    "\n",
    "# Combine\n",
    "response = model.query(\n",
    "    prompt=f\"Context: {context}\\n\\nQuestion: {query}\",\n",
    "    model=model\n",
    ")\n",
    "```\n",
    "\n",
    "**2. Few-Shot + Fine-Tuning**\n",
    "- Fine-tune for general behavior\n",
    "- Few-shot for specific edge cases\n",
    "\n",
    "```python\n",
    "# Use fine-tuned model as base\n",
    "model = \"zava-fine-tuned\"\n",
    "\n",
    "# Add few-shot for special cases\n",
    "if is_complex_query(query):\n",
    "    prompt_with_examples = add_examples(query)\n",
    "    response = model.query(prompt_with_examples)\n",
    "else:\n",
    "    response = model.query(query)\n",
    "```\n",
    "\n",
    "**3. Distillation + RAG**\n",
    "- Distill for cost/speed\n",
    "- RAG for factual grounding\n",
    "\n",
    "```python\n",
    "# Distilled GPT-4o-mini model\n",
    "model = \"zava-distilled-mini\"\n",
    "\n",
    "# Retrieve current data\n",
    "context = retrieve_from_search(query)\n",
    "\n",
    "# Query with context\n",
    "response = model.query(f\"Context: {context}\\n\\nQ: {query}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa802d99",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Training Data Best Practices\n",
    "\n",
    "### 1. Quality Over Quantity\n",
    "\n",
    "**Better:**\n",
    "- 100 high-quality, diverse examples\n",
    "- Carefully curated and validated\n",
    "- Representative of real use cases\n",
    "\n",
    "**Worse:**\n",
    "- 1000 low-quality, repetitive examples\n",
    "- Automatically generated without review\n",
    "- Not representative of actual queries\n",
    "\n",
    "### 2. Diversity in Training Data\n",
    "\n",
    "Cover different:\n",
    "- **Query types** (questions, requests, commands)\n",
    "- **Complexity levels** (simple to multi-step)\n",
    "- **Product categories** (paint, tools, hardware)\n",
    "- **Customer intents** (search, compare, fact-check)\n",
    "\n",
    "```jsonl\n",
    "{\"messages\": [{\"role\": \"user\", \"content\": \"What paint?\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "{\"messages\": [{\"role\": \"user\", \"content\": \"Compare latex vs oil-based paint for outdoor furniture\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "{\"messages\": [{\"role\": \"user\", \"content\": \"Is PFIP000002 available in blue?\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "```\n",
    "\n",
    "### 3. Validation Split\n",
    "\n",
    "**Don't use all data for training:**\n",
    "\n",
    "```\n",
    "Total: 1000 examples\n",
    "  ‚Üì\n",
    "Training: 800 (80%)\n",
    "Validation: 200 (20%)\n",
    "```\n",
    "\n",
    "**Use validation set to:**\n",
    "- Detect overfitting\n",
    "- Tune hyperparameters\n",
    "- Measure generalization\n",
    "\n",
    "### 4. Consistent Formatting\n",
    "\n",
    "```jsonl\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are Cora...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are Cora...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "```\n",
    "\n",
    "**Keep consistent:**\n",
    "- System message (same across all)\n",
    "- Response structure\n",
    "- Terminology and naming\n",
    "- Tone and style\n",
    "\n",
    "### 5. Token Budget Awareness\n",
    "\n",
    "```python\n",
    "# Check before training\n",
    "def validate_training_data(data_file):\n",
    "    total_tokens = 0\n",
    "    \n",
    "    with open(data_file) as f:\n",
    "        for line in f:\n",
    "            example = json.loads(line)\n",
    "            tokens = count_tokens(example)\n",
    "            total_tokens += tokens\n",
    "            \n",
    "            if tokens > 4096:  # Example too long\n",
    "                print(f\"Warning: Example exceeds limit: {tokens} tokens\")\n",
    "    \n",
    "    epochs = 3\n",
    "    cost = (total_tokens * epochs * 0.008) / 1000  # Example rate\n",
    "    \n",
    "    print(f\"Total tokens: {total_tokens}\")\n",
    "    print(f\"Estimated cost: ${cost:.2f}\")\n",
    "    \n",
    "    return total_tokens < 1_000_000  # Example limit\n",
    "```\n",
    "\n",
    "### 6. Iterative Improvement\n",
    "\n",
    "**Process:**\n",
    "```\n",
    "1. Create initial training set (100 examples)\n",
    "   ‚Üì\n",
    "2. Fine-tune model\n",
    "   ‚Üì\n",
    "3. Test on validation set\n",
    "   ‚Üì\n",
    "4. Identify failure patterns\n",
    "   ‚Üì\n",
    "5. Add examples addressing failures\n",
    "   ‚Üì\n",
    "6. Repeat steps 2-5\n",
    "```\n",
    "\n",
    "**Each iteration improves specific weaknesses.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a72e555",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluating Custom Models\n",
    "\n",
    "### Before vs After Comparison\n",
    "\n",
    "**Test on validation set:**\n",
    "\n",
    "```python\n",
    "validation_queries = [...]  # Held-out test set\n",
    "\n",
    "# Test base model\n",
    "base_results = evaluate_model(\"gpt-4o-mini\", validation_queries)\n",
    "\n",
    "# Test fine-tuned model\n",
    "custom_results = evaluate_model(\"zava-fine-tuned\", validation_queries)\n",
    "\n",
    "# Compare\n",
    "comparison = {\n",
    "    \"Base Model\": {\n",
    "        \"Accuracy\": base_results.accuracy,\n",
    "        \"Tone Match\": base_results.tone_score,\n",
    "        \"Avg Tokens\": base_results.avg_tokens\n",
    "    },\n",
    "    \"Fine-Tuned\": {\n",
    "        \"Accuracy\": custom_results.accuracy,\n",
    "        \"Tone Match\": custom_results.tone_score,\n",
    "        \"Avg Tokens\": custom_results.avg_tokens\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### Key Metrics\n",
    "\n",
    "**1. Task Performance**\n",
    "- Did accuracy improve?\n",
    "- Are responses more relevant?\n",
    "- Better product recommendations?\n",
    "\n",
    "**2. Style Consistency**\n",
    "- Matches brand voice?\n",
    "- Consistent tone across queries?\n",
    "- Appropriate formality level?\n",
    "\n",
    "**3. Efficiency**\n",
    "- Shorter prompts needed?\n",
    "- Faster responses?\n",
    "- Lower token usage?\n",
    "\n",
    "**4. Error Reduction**\n",
    "- Fewer hallucinations?\n",
    "- Better handling of edge cases?\n",
    "- More graceful failures?\n",
    "\n",
    "### A/B Testing in Production\n",
    "\n",
    "```python\n",
    "# Split traffic\n",
    "def route_query(query):\n",
    "    if random.random() < 0.5:\n",
    "        return base_model.query(query)\n",
    "    else:\n",
    "        return fine_tuned_model.query(query)\n",
    "\n",
    "# Track metrics\n",
    "metrics = {\n",
    "    \"base_model\": {\"satisfaction\": [], \"latency\": []},\n",
    "    \"fine_tuned\": {\"satisfaction\": [], \"latency\": []}\n",
    "}\n",
    "\n",
    "# After 1000 queries, compare\n",
    "analyze_ab_test(metrics)\n",
    "```\n",
    "\n",
    "### Regression Testing\n",
    "\n",
    "**Ensure fine-tuning didn't break existing capabilities:**\n",
    "\n",
    "```python\n",
    "# Test suite\n",
    "regression_tests = [\n",
    "    {\"input\": \"What is 2+2?\", \"expected\": \"4\"},\n",
    "    {\"input\": \"What is the capital of France?\", \"expected\": \"Paris\"},\n",
    "    # ... general knowledge tests\n",
    "]\n",
    "\n",
    "# Both models should pass\n",
    "assert all(test_model(base_model, regression_tests))\n",
    "assert all(test_model(fine_tuned, regression_tests))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e220855",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Terminology Quick Reference\n",
    "\n",
    "| Term | Simple Definition |\n",
    "|------|-------------------|\n",
    "| **Fine-Tuning** | Training a model further on your specific data |\n",
    "| **Distillation** | Training a small model to mimic a large model |\n",
    "| **Few-Shot Prompting** | Including example responses in the prompt |\n",
    "| **Supervised Fine-Tuning (SFT)** | Fine-tuning with labeled input-output pairs |\n",
    "| **JSONL** | JSON Lines format - one JSON object per line |\n",
    "| **Training Data** | Examples used to teach the model your patterns |\n",
    "| **Validation Data** | Examples held out to test model performance |\n",
    "| **Epoch** | One complete pass through training data |\n",
    "| **Token** | Unit of text (~4 characters) used for billing |\n",
    "| **Hyperparameters** | Settings that control training (e.g., learning rate) |\n",
    "| **Overfitting** | Model memorizes training data, doesn't generalize |\n",
    "| **Teacher Model** | Large model used as source in distillation |\n",
    "| **Student Model** | Small model being trained in distillation |\n",
    "| **Custom Grader** | Function that evaluates response quality |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d95c68",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "Now that you understand model customization concepts, you're ready to fine-tune and distill your own models!\n",
    "\n",
    "### Hands-On Notebooks in This Section\n",
    "\n",
    "- **`31-basic-finetuning.ipynb`** - Fine-tune a model on Zava product data\n",
    "  - Prepare training data in JSONL format\n",
    "  - Validate token counts and optimize data\n",
    "  - Submit fine-tuning job to Azure OpenAI\n",
    "  - Deploy and test fine-tuned model\n",
    "  - Compare base vs. fine-tuned performance\n",
    "\n",
    "- **`32-custom-grader.ipynb`** - Build custom evaluators for quality control\n",
    "  - Create custom grading functions\n",
    "  - Filter training data by quality\n",
    "  - Improve training data quality\n",
    "  - Validate responses meet standards\n",
    "\n",
    "- **`33-distill-finetuning.ipynb`** - Distill GPT-4o knowledge to GPT-4o-mini\n",
    "  - Generate teacher responses from GPT-4o\n",
    "  - Create student training dataset\n",
    "  - Fine-tune GPT-4o-mini on teacher outputs\n",
    "  - Compare student vs. teacher quality\n",
    "  - Calculate cost savings from distillation\n",
    "\n",
    "### Recommended Learning Path\n",
    "\n",
    "1. **Start here** ‚Üí Understand concepts (this notebook)\n",
    "2. **Next** ‚Üí Basic fine-tuning (`31-basic-finetuning.ipynb`)\n",
    "3. **Then** ‚Üí Quality control (`32-custom-grader.ipynb`)\n",
    "4. **Advanced** ‚Üí Distillation (`33-distill-finetuning.ipynb`)\n",
    "5. **After** ‚Üí Move to evaluation labs (measure improvements)\n",
    "6. **Finally** ‚Üí Deploy custom models to production\n",
    "\n",
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "For deeper understanding:\n",
    "\n",
    "- **[Fine-Tuning Guide](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning)** - Azure OpenAI fine-tuning documentation\n",
    "- **[Preparing Training Data](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning?tabs=python#prepare-training-data)** - Data format and best practices\n",
    "- **[Model Distillation](https://learn.microsoft.com/azure/ai-studio/concepts/model-distillation)** - Knowledge transfer concepts\n",
    "- **[Token Optimization](https://learn.microsoft.com/azure/ai-services/openai/how-to/token-optimization)** - Reducing costs\n",
    "- **[Evaluation Metrics](https://learn.microsoft.com/azure/ai-studio/concepts/evaluation-metrics-built-in)** - Measuring model quality\n",
    "\n",
    "---\n",
    "\n",
    "Ready to fine-tune your first model? Open `31-basic-finetuning.ipynb` to get started! üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
